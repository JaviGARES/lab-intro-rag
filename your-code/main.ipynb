{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsnCPbdkxYZd"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <h1 style=\"color: #FF6347;\">Self-Guided Lab: Retrieval-Augmented Generation (RAGs)</h1>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZp4BQAVxYZj"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExZ3FsdzRveTBrenMxM3VnbDMwaTJxN2NnZm50aGFibXk1NzNnY2Q0MCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/LR5ZBwZHv02lmpVoEU/giphy.gif\" alt=\"NLP Gif\" style=\"width: 300px; height: 150px; object-fit: cover; object-position: center;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gizk6HCYxYZo"
      },
      "source": [
        "<h1 style=\"color: #FF6347;\">Data Storage & Retrieval</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW5UOI8ZxYZp"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">PyPDFLoader</h2>\n",
        "\n",
        "`PyPDFLoader` is a lightweight Python library designed to streamline the process of loading and parsing PDF documents for text processing tasks. It is particularly useful in Retrieval-Augmented Generation workflows where text extraction from PDFs is required.\n",
        "\n",
        "- **What Does PyPDFLoader Do?**\n",
        "  - Extracts text from PDF files, retaining formatting and layout.\n",
        "  - Simplifies the preprocessing of document-based datasets.\n",
        "  - Supports efficient and scalable loading of large PDF collections.\n",
        "\n",
        "- **Key Features:**\n",
        "  - Compatible with popular NLP libraries and frameworks.\n",
        "  - Handles multi-page PDFs and embedded images (e.g., OCR-compatible setups).\n",
        "  - Provides flexible configurations for structured text extraction.\n",
        "\n",
        "- **Use Cases:**\n",
        "  - Preparing PDF documents for retrieval-based systems in RAGs.\n",
        "  - Automating the text extraction pipeline for document analysis.\n",
        "  - Creating datasets from academic papers, technical manuals, and reports.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install langchain langchain_community pypdf\n",
        "%pip install termcolor langchain_openai langchain-huggingface sentence-transformers chromadb langchain_chroma tiktoken openai python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6heKZkQUxYZr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRS44B2XxYZs",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "<h3 style=\"color: #FF8C00;\">Loading the Documents</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cuREtJRixYZt"
      },
      "outputs": [],
      "source": [
        "# File path for the document\n",
        "\n",
        "file_path = r\"C:\\Users\\jgest\\Desktop\\IRONHACK\\labs\\week7\\day5\\lab-intro-rag\\ai-for-everyone.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz_8SOLxxYZt"
      },
      "source": [
        "<h3 style=\"color: #FF8C00;\">Documents into pages</h3>\n",
        "\n",
        "The `PyPDFLoader` library allows efficient loading and splitting of PDF documents into smaller, manageable parts for NLP tasks.\n",
        "\n",
        "This functionality is particularly useful in workflows requiring granular text processing, such as Retrieval-Augmented Generation (RAG).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_b5Z_45UxYZu",
        "outputId": "a600d69f-14fe-4492-f236-97261d6ff36c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "297"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load and split the document\n",
        "loader = PyPDFLoader(file_path)\n",
        "pages = loader.load_and_split()\n",
        "len(pages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt50NRQaxYZv"
      },
      "source": [
        "<h3 style=\"color: #FF8C00;\">Pages into Chunks</h3>\n",
        "\n",
        "\n",
        "####  RecursiveCharacterTextSplitter in LangChain\n",
        "\n",
        "The `RecursiveCharacterTextSplitter` is the **recommended splitter** in LangChain when you want to break down long documents into smaller, semantically meaningful chunks — especially useful in **RAG pipelines**, where clean context chunks lead to better LLM responses.\n",
        "\n",
        "####  Parameters\n",
        "\n",
        "| Parameter       | Description                                                                 |\n",
        "|-----------------|-----------------------------------------------------------------------------|\n",
        "| `chunk_size`    | The **maximum number of characters** allowed in a chunk (e.g., `1000`).     |\n",
        "| `chunk_overlap` | The number of **overlapping characters** between consecutive chunks (e.g., `200`). This helps preserve context continuity. |\n",
        "\n",
        "####  How it works\n",
        "`RecursiveCharacterTextSplitter` attempts to split the text **intelligently**, trying the following separators in order:\n",
        "1. Paragraphs (`\"\\n\\n\"`)\n",
        "2. Lines (`\"\\n\"`)\n",
        "3. Sentences or words (`\" \"`)\n",
        "4. Individual characters (as a last resort)\n",
        "\n",
        "This makes it ideal for handling **natural language documents**, such as PDFs, articles, or long reports, without breaking sentences or paragraphs in awkward ways.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1096"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "len(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####  Alternative: CharacterTextSplitter\n",
        "\n",
        "`CharacterTextSplitter` is a simpler splitter that breaks text into chunks based **purely on character count**, without trying to preserve any natural language structure.\n",
        "\n",
        "##### Example:\n",
        "```python\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "````\n",
        "\n",
        "This method is faster and more predictable but may split text in the middle of a sentence or paragraph, which can hurt performance in downstream tasks like retrieval or QA.\n",
        "\n",
        "---\n",
        "\n",
        "#### Comparison Table\n",
        "\n",
        "| Feature                        | RecursiveCharacterTextSplitter | CharacterTextSplitter     |\n",
        "| ------------------------------ | ------------------------------ | ------------------------- |\n",
        "| Structure-aware splitting      |  Yes                          |  No                      |\n",
        "| Preserves sentence/paragraphs  |  Yes                          |  No                      |\n",
        "| Risk of splitting mid-sentence |  Minimal                     |  High                   |\n",
        "| Ideal for RAG/document QA      |  Highly recommended           |  Only if structured text |\n",
        "| Performance speed              |  Slightly slower             |  Faster                  |\n",
        "\n",
        "---\n",
        "\n",
        "#### Recommendation\n",
        "\n",
        "Use `RecursiveCharacterTextSplitter` for most real-world document processing tasks, especially when building RAG pipelines or working with structured natural language content like PDFs or articles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices for Choosing Chunk Size in RAG\n",
        "\n",
        "### Best Practices for Chunk Size in RAG\n",
        "\n",
        "| Factor                      | Recommendation                                                                                                                                                                                          |\n",
        "| ---------------------------| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **LLM context limit**       | Choose a chunk size that lets you retrieve multiple chunks **without exceeding the model’s token limit**. For example, GPT-4o supports 128k tokens, but with GPT-3.5 (16k) or GPT-4 (32k), keep it modest. |\n",
        "| **Chunk size (in characters)** | Typically: **500–1,000 characters** per chunk → ~75–200 tokens. This fits well for retrieval + prompt without context overflow.                                                                           |\n",
        "| **Chunk size (in tokens)**  | If using token-based splitter (e.g. `TokenTextSplitter`): aim for **100–300 tokens** per chunk.                                                                                                            |\n",
        "| **Chunk overlap**           | Use **overlap of 10–30%** (e.g., 100–300 characters or ~50 tokens) to preserve context across chunk boundaries and avoid cutting off important ideas mid-sentence.                                        |\n",
        "| **Document structure**      | Use **`RecursiveCharacterTextSplitter`** to preserve semantic boundaries (paragraphs, sentences) instead of arbitrary cuts.                                                                                |\n",
        "| **Task type**               | For **question answering**, smaller chunks (~500–800 chars) reduce noise.<br>For **summarization**, slightly larger chunks (~1000–1500) are OK.                                                          |\n",
        "| **Embedding model**         | Some models (e.g., `text-embedding-3-large`) can handle long input. But still, smaller chunks give **finer-grained retrieval**, which improves relevance.                                                  |\n",
        "| **Query type**              | If users ask **very specific questions**, small focused chunks are better. For broader queries, bigger chunks might help.                                                                                  |\n",
        "\n",
        "\n",
        "### Rule of Thumb\n",
        "\n",
        "| Use Case                 | Chunk Size      | Overlap |\n",
        "| ------------------------| --------------- | ------- |\n",
        "| Factual Q&A              | 500–800 chars   | 100–200 |\n",
        "| Summarization            | 1000–1500 chars | 200–300 |\n",
        "| Technical documents      | 400–700 chars   | 100–200 |\n",
        "| Long reports/books       | 800–1200 chars  | 200–300 |\n",
        "| Small LLMs (≤16k tokens) | ≤800 chars      | 100–200 |\n",
        "\n",
        "\n",
        "### Avoid\n",
        "\n",
        "- Chunks >2000 characters: risks context overflow.\n",
        "- No overlap: may lose key information between chunks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg15RjVPxYZw"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">Embeddings</h2>\n",
        "\n",
        "Embeddings transform text into dense vector representations, capturing semantic meaning and contextual relationships. They are essential for efficient document retrieval and similarity analysis.\n",
        "\n",
        "- **What are OpenAI Embeddings?**\n",
        "  - Pre-trained embeddings like `text-embedding-3-large` generate high-quality vector representations for text.\n",
        "  - Encapsulate semantic relationships in the text, enabling robust NLP applications.\n",
        "\n",
        "- **Key Features of `text-embedding-3-large`:**\n",
        "  - Large-scale embedding model optimized for accuracy and versatility.\n",
        "  - Handles diverse NLP tasks, including retrieval, classification, and clustering.\n",
        "  - Ideal for applications with high-performance requirements.\n",
        "\n",
        "- **Benefits:**\n",
        "  - Reduces the need for extensive custom training.\n",
        "  - Provides state-of-the-art performance in retrieval-augmented systems.\n",
        "  - Compatible with RAGs to create powerful context-aware models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "L0xDxElwxYZw"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_WRIo3_0xYZx",
        "outputId": "78bfbbf3-9d25-4e31-bdbc-3e932e6bbfec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MNZfTng5xYZz",
        "outputId": "db1a7c85-ef9f-447e-92cd-9d097e959847"
      },
      "outputs": [],
      "source": [
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsSA7RKvxYZz"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">ChromaDB</h2>\n",
        "\n",
        "ChromaDB is a versatile vector database designed for efficiently storing and retrieving embeddings. It integrates seamlessly with embedding models to enable high-performance similarity search and context-based retrieval.\n",
        "\n",
        "### Workflow Overview:\n",
        "- **Step 1:** Generate embeddings using a pre-trained model (e.g., OpenAI's `text-embedding-3-large`).\n",
        "- **Step 2:** Store the embeddings in ChromaDB for efficient retrieval and similarity calculations.\n",
        "- **Step 3:** Use the stored embeddings to perform searches, matching, or context-based retrieval.\n",
        "\n",
        "### Key Features of ChromaDB:\n",
        "- **Scalability:** Handles large-scale datasets with optimized indexing and search capabilities.\n",
        "- **Speed:** Provides fast and accurate retrieval of embeddings for real-time applications.\n",
        "- **Integration:** Supports integration with popular frameworks and libraries for embedding generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "brKe6wUgxYZ0"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VkjHR-RkxYZ0",
        "outputId": "bc11bda9-f283-457a-f584-5a06b95c4dd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChromaDB created with document embeddings.\n"
          ]
        }
      ],
      "source": [
        "db = Chroma.from_documents(chunks, embeddings, persist_directory=\"./chroma_db_LAB\")\n",
        "print(\"ChromaDB created with document embeddings.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27OdN1IVxYZ1"
      },
      "source": [
        "<h1 style=\"color: #FF6347;\">Retrieving Documents</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice1: Write a user question that someone might ask about your book’s topic or content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XiLv-TfrxYZ1"
      },
      "outputs": [],
      "source": [
        "user_question = \"How does the book explain the relationship between AI, digital capitalism, and existing social inequalities?\" # User question\n",
        "retrieved_docs = db.similarity_search(user_question, k=10) # k is the number of documents to retrieve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qgWsh50JxYZ1",
        "outputId": "c8640c5d-5955-471f-fdd2-37096f5f68c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1:\n",
            "vestigates the normative projections of what \n",
            "AI should be and what it should do. This section poses critical questions about \n",
            "how AI needs to debunk the myths surrounding it.\n",
            "Part 3: AI Power and Inequalities – advances the debate around AI by criti -\n",
            "cally examining what ‘ AI for Everyone?’ means. This is dealing with the root of \n",
            "the problem: who will benefit from AI is ultimately down to who has the power \n",
            "to decide. These contributions look at how AI capitalism is organised, what \n",
            "(new) inequalities it might bring about and how we can fight back.\n",
            "Why do we need a book on AI for Everyone? and why do we need it now? \n",
            "The 2007–2008 financial crisis, and the resulting global economic crisis, has not \n",
            "only brought about a decade of austerity in large parts of the Western world; \n",
            "it has also been the context in which social media and digital platforms have \n",
            "transformed into behemoths. Tech companies are now dominating the top 10\n",
            "Document 2:\n",
            "tends long-standing debates on modes of \n",
            "capitalism that significantly shape the circumstances of working people whilst \n",
            "limiting their ability to influence decisions that govern their lives.\n",
            "Document 3:\n",
            " came along with observations that AI can \n",
            "not only supercharge innovation and bring about economic prosperity but also  \n",
            "lead to inequalities and unfairness. \n",
            "This book contributes to this debate by critically reflecting on how we  \n",
            "should think about AI and the relationship between humans and machines. \n",
            "It analyses the discourses and myths that exist around AI; what it will enable\n"
          ]
        }
      ],
      "source": [
        "# Display top results\n",
        "for i, doc in enumerate(retrieved_docs[:3]): # Display top 3 results\n",
        "    print(f\"Document {i+1}:\\n{doc.page_content[36:1000]}\") # Display content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuGK8gL6xYZ1"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">Preparing Content for GenAI</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2iB3lZqHxYZ2"
      },
      "outputs": [],
      "source": [
        "def _get_document_prompt(docs):\n",
        "    prompt = \"\\n\"\n",
        "    for doc in docs:\n",
        "        prompt += \"\\nContent:\\n\"\n",
        "        prompt += doc.page_content + \"\\n\\n\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2okzmuADxYZ2",
        "outputId": "0aa6cdca-188d-40e0-f5b4-8888d3549ea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context formatted for GPT model.\n"
          ]
        }
      ],
      "source": [
        "# Generate a formatted context from the retrieved documents\n",
        "formatted_context = _get_document_prompt(retrieved_docs)\n",
        "print(\"Context formatted for GPT model.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Content:\n",
            "lar and scholarly discussions and investigates the normative projections of what \n",
            "AI should be and what it should do. This section poses critical questions about \n",
            "how AI needs to debunk the myths surrounding it.\n",
            "Part 3: AI Power and Inequalities – advances the debate around AI by criti -\n",
            "cally examining what ‘ AI for Everyone?’ means. This is dealing with the root of \n",
            "the problem: who will benefit from AI is ultimately down to who has the power \n",
            "to decide. These contributions look at how AI capitalism is organised, what \n",
            "(new) inequalities it might bring about and how we can fight back.\n",
            "Why do we need a book on AI for Everyone? and why do we need it now? \n",
            "The 2007–2008 financial crisis, and the resulting global economic crisis, has not \n",
            "only brought about a decade of austerity in large parts of the Western world; \n",
            "it has also been the context in which social media and digital platforms have \n",
            "transformed into behemoths. Tech companies are now dominating the top 10\n",
            "\n",
            "\n",
            "Content:\n",
            "ment of AI across social life. AI extends long-standing debates on modes of \n",
            "capitalism that significantly shape the circumstances of working people whilst \n",
            "limiting their ability to influence decisions that govern their lives.\n",
            "\n",
            "\n",
            "Content:\n",
            "other. These first critical insights came along with observations that AI can \n",
            "not only supercharge innovation and bring about economic prosperity but also  \n",
            "lead to inequalities and unfairness. \n",
            "This book contributes to this debate by critically reflecting on how we  \n",
            "should think about AI and the relationship between humans and machines. \n",
            "It analyses the discourses and myths that exist around AI; what it will enable\n",
            "\n",
            "\n",
            "Content:\n",
            "Towards Data Justice Unionism? 271\n",
            "class owns the means of organising the means of production. Importantly, this \n",
            "does not necessarily make away with the exploitation of labour in value chains. \n",
            "As Srnicek (2020) has pointed out, AI systems rely not just on vast amounts of \n",
            "data, but on significant computational power and control over labour to drive \n",
            "monopolisation. We have a growing economy based on what Gray and Suri \n",
            "(2019, ix) refer to as ‘ ghost work’: a new digital assembly line that aggregates \n",
            "the collective input of distributed workers, ships pieces of projects rather than \n",
            "products, and operates continuously across a host of economic sectors in order \n",
            "for AI systems to function. \n",
            "The implications of AI for labour therefore extend from the workplace to \n",
            "the reorganisation of employment through to the operations of capital upon \n",
            "which AI depends and advances. The use of AI in automated hiring systems,\n",
            "\n",
            "\n",
            "Content:\n",
            "to an already skewed social landscape (Eubanks 2018). There’s more data about \n",
            "the poor and marginalised because they are already most surveilled, and they \n",
            "are most surveilled because our social systems already categorise them as trou-\n",
            "blesome. As a result, any unfairness that algorithms add to the mix will fall \n",
            "more heavily on those who are already struggling the most. However, it’s not \n",
            "only or even mainly data that shapes the politics of AI.\n",
            "Langdon Winner wrote about the way particular technologies appear to \n",
            "have an inherent compatibility with particular socio-political systems (Winner \n",
            "2020), so it’s fair to ask what feedback loops connect AI and the societies into \n",
            "which it has emerged. This attentiveness may help to bring neglected features  \n",
            "to the fore, to remind us of framings that are so pervasive they are usually \n",
            "ignored or to highlight new dynamics that are going to change more than just\n",
            "\n",
            "\n",
            "Content:\n",
            "the reorganisation of employment through to the operations of capital upon \n",
            "which AI depends and advances. The use of AI in automated hiring systems,  \n",
            "performance assessment tools, scheduling, and other forms of algorithmic man-\n",
            "agement in the workplace (platforms or otherwise) intersect with broader trans-\n",
            "formations in the economy and dynamics of capitalism in which developments \n",
            "in AI are embedded. These different concerns highlight the many complex and \n",
            "intricate ways AI impacts on the experiences of working people, the way their \n",
            "work is organised and how it is valued, and their ability to influence decisions \n",
            "that govern their lives. Y et, as I will go on to outline below, workers’ voices and \n",
            "union perspectives have been notably absent from AI governance debates that \n",
            "have instead overwhelmingly championed liberal frameworks based on citizen \n",
            "and consumer rights. If we are to contend with AI in relation to the advance -\n",
            "\n",
            "\n",
            "Content:\n",
            "Introduction: Why We Need Critical Perspectives on AI  3\n",
            "of the most valuable companies in the world (Verdegem 2021). Austerity has \n",
            "also led to growing inequalities and political polarisation, bringing right-wing \n",
            "authoritarian politics into power in a number of countries (Fuchs 2018). A \n",
            "world already cracked by economic uncertainty and the looming threat of \n",
            "climate change was then shaken in 2020 by a global pandemic. COVID-19 \n",
            "has massively impacted the global economy, on a much larger scale than the \n",
            "2007–2008 crisis. On top of this, the pandemic has also resulted in an even \n",
            "bigger dependence and dominance of tech platforms such as Amazon, Alibaba, \n",
            "Google and Tencent. These companies are, not surprisingly, also leading AI \n",
            "companies. Only a small number of corporations have the necessary compu -\n",
            "tational power to develop AI systems, are financially strong enough to hire the \n",
            "brightest AI talent and have access to the gigantic datasets that are needed to\n",
            "\n",
            "\n",
            "Content:\n",
            "when talking about AI and intelligent systems. Angela Daly, S. Kate Devitt and  \n",
            "Monique Mann (Chapter 7) introduce and discuss their Good Data approach in \n",
            "order to overcome the limitations of AI ethics and governance. James Steinhoff \n",
            "(Chapter 8) critically analyses the social reconfiguration of AI and discusses \n",
            "the central questions about utility and feasibility. Benedetta Brevini (Chapter 9)  \n",
            "analyses AI policies in Europe and unpacks some of the myths around AI \n",
            "that legitimate capitalism. Alkim Almila Akdag Salah ( Chapter 10 ) reflects \n",
            "on how the discourses of artistic computational production have changed and  \n",
            "how myths about AI need to be uncovered in this context.\n",
            "Part 3: AI Power and Inequalities involves five contributions. Carrie O’Connell \n",
            "and Chad Van de Wiele ( Chapter 11) revisit Wiener’s cybernetic prediction \n",
            "as the theoretical foundation of AI and make a plea how we need to uncover \n",
            "the black box of what is behind prediction and simulation. Jernej A. Prodnik\n",
            "\n",
            "\n",
            "Content:\n",
            "to pass for social class as well as race; how it seems to always be the poorest \n",
            "and most marginalised who bear the brunt of collateral damage from algorith-\n",
            "mic systems even when the bureaucrats involved are making sincere efforts \n",
            "to be fair (which they often aren’t) (Eubanks 2018). The data demands of AI \n",
            "mean that the pattern of having to trade private personal information for ser -\n",
            "vices will become even more invasive. The optimisations of AI act as an inverse \n",
            "intersectionality, applying additional downward pressure on existing fissures in \n",
            "the social fabric. Like Eubanks, we should be asking what specific forms these \n",
            "fractures will take, and how to recognise them. One marker will be the emer -\n",
            "gence of machinic moralism. The more that AI is seen as a solution to austerity, \n",
            "the more its classifications and rankings will be enrolled in the rationing of \n",
            "goods and the assigning of sanctions. AI will be put in the position of decid -\n",
            "\n",
            "\n",
            "Content:\n",
            "Tech-Determinism, Tech-Solutionism and AI\n",
            "The technological deterministic argument that technology can and will fix  \n",
            "capitalism – and its intrinsic power to exacerbate inequalities of economic, \n",
            "racial, gender forms – is far from being a recent elaboration (Gilder 1990; \n",
            "Negroponte 1998). To use the words of Mosco, ‘one generation after another \n",
            "has renewed the belief that, whatever was said about earlier technologies, the \n",
            "latest one will fulfil a radical and revolutionary promise’ (Mosco 2004, 21; \n",
            "Brevini 2020). Mosco (2004) rightly reminds us of James Carey’s (1992) work \n",
            "that discussed how machines have often been framed employing a powerful \n",
            "religious ethos: ‘in contemporary popular commentary and even in technical \n",
            "discussions of new communications technology, the historic religious under -\n",
            "current has never been eliminated from our thought’ (Carey 1992, 18).\n",
            "As a result, technology becomes the most powerful weapon purporting to lift\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(formatted_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzIczQNTxYZ2"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">ChatBot Architecture</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice2: Write a prompt that is relevant and tailored to the content and style of your book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tqxVh9s3xYZ3",
        "outputId": "97cca95d-4ab3-44d8-a76c-5713aad387d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt constructed.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "## SYSTEM ROLE\n",
        "You are a helpful academic assistant helping a student understand arguments from the book *AI for Everyone? Critical Perspectives on AI*.\n",
        "You are given excerpts from the book as context and a user question.\n",
        "\n",
        "## USER QUESTION\n",
        "The user has asked:\n",
        "{user_question}\n",
        "\n",
        "## CONTEXT\n",
        "Here is the relevant content from the technical books:\n",
        "'''\n",
        "{formatted_context}\n",
        "'''\n",
        "\n",
        "## GUIDELINES\n",
        "1. **Accuracy**:\n",
        "    - Only use the content in the `CONTEXT` section to answer.\n",
        "    - Base your answer ONLY on the context above.\n",
        "    - If the context is not sufficient to fully answer, say that explicitly and explain what is missing.\n",
        "    - Emphasise the book's critical perspective on AI (power, inequalities, digital capitalism, labour, data justice, AI myths).\n",
        "    - When appropriate, connect different themes (e.g. AI ethics, data, capitalism, labour) instead of treating them in isolation.\n",
        "\n",
        "    \n",
        "2. **Transparency**:\n",
        "   - Reference the book's name and page numbers when providing information.\n",
        "   - Do not speculate or provide opinions.\n",
        "\n",
        "\n",
        "3. **Clarity**:\n",
        "   - Use simple, professional, and concise language.\n",
        "   - Format your response in Markdown for readability.\n",
        "\n",
        "## TASK\n",
        "1. Answer the user's question **directly** if possible.\n",
        "2. Point the user to relevant parts of the documentation.\n",
        "3. Provide the response in the following format:\n",
        "\n",
        "## RESPONSE FORMAT\n",
        "'''\n",
        "# [Brief Title of the Answer]\n",
        "[Answer in simple, clear text.]\n",
        "\n",
        "**Source**:\n",
        "• [Book Title], Page(s): [...]\n",
        "'''\n",
        "\"\"\"\n",
        "print(\"prompt constructed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0mjkQJ_ZxYZ3"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice3: Tune parameters like temperature, and penalties to control how creative, focused, or varied the model's responses are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ylypRWRlxYZ4"
      },
      "outputs": [],
      "source": [
        "# Set up GPT client and parameters\n",
        "client = openai.OpenAI()\n",
        "model_params = {\n",
        "    'model': 'gpt-4o',\n",
        "    'temperature': 0.4,  # Increase creativity\n",
        "    'max_tokens': 2000,  # Allow for longer responses\n",
        "    'top_p': 0.9,        # Use nucleus sampling\n",
        "    'frequency_penalty': 0.3,  # Reduce repetition\n",
        "    'presence_penalty': 0.5   # Encourage new topics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8e942xDxYZ4"
      },
      "source": [
        "<h1 style=\"color: #FF6347;\">Response</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4eXZO4pIxYZ4"
      },
      "outputs": [],
      "source": [
        "messages = [{'role': 'user', 'content': prompt}]\n",
        "completion = client.chat.completions.create(messages=messages, **model_params, timeout=120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wLPAcchBxYZ5",
        "outputId": "976c7800-16ed-41fe-c4cf-58f60d3230d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'''\n",
            "# The Relationship Between AI, Digital Capitalism, and Social Inequalities\n",
            "\n",
            "The book *AI for Everyone? Critical Perspectives on AI* explores the intricate relationship between AI, digital capitalism, and existing social inequalities. It critically examines how AI is embedded within the broader transformations of capitalism and how it perpetuates or exacerbates social inequalities. The text highlights several key points:\n",
            "\n",
            "1. **AI and Capitalism**: The book discusses how AI systems are deeply intertwined with capitalist structures, particularly in the way they rely on vast data resources and computational power controlled by a few dominant tech companies. These corporations, such as Amazon, Google, and Tencent, have become central players in the global economy due to their ability to harness AI technologies (Page 3).\n",
            "\n",
            "2. **Labour Implications**: AI's impact on labour is significant as it reorganizes employment through automated hiring systems and algorithmic management tools. This reorganization often limits workers' influence over decisions that affect their lives, thus reinforcing existing power imbalances within capitalist economies (Page 271).\n",
            "\n",
            "3. **Social Inequalities**: The book also addresses how AI can contribute to social inequalities by disproportionately affecting marginalized communities. Since these groups are already heavily surveilled, any biases inherent in AI systems tend to exacerbate their struggles (Page 271). Moreover, the data demands of AI can lead to more invasive practices that further entrench existing societal fissures.\n",
            "\n",
            "4. **Technological Determinism and Myths**: There is a critique of the deterministic belief that technology alone can solve societal issues like inequality. The text argues that such views overlook the socio-political contexts in which technologies like AI operate and fail to address the root causes of inequality (Page 21).\n",
            "\n",
            "Overall, the book calls for critical reflection on these dynamics to uncover myths surrounding AI and to consider whose interests are served by its development.\n",
            "\n",
            "**Source**:\n",
            "• *AI for Everyone? Critical Perspectives on AI*, Pages: 3, 21, 271\n",
            "'''\n"
          ]
        }
      ],
      "source": [
        "answer = completion.choices[0].message.content\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXVNXPwLxYaT"
      },
      "source": [
        "<img src=\"https://miro.medium.com/v2/resize:fit:824/1*GK56xmDIWtNQAD_jnBIt2g.png\" alt=\"NLP Gif\" style=\"width: 500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldybhlqKxYaT"
      },
      "source": [
        "<h2 style=\"color: #FF6347;\">Cosine Similarity</h2>\n",
        "\n",
        "**Cosine similarity** is a metric used to measure the alignment or similarity between two vectors, calculated as the cosine of the angle between them. It is the **most common metric used in RAG pipelines** for vector retrieval.. It provides a scale from -1 to 1:\n",
        "\n",
        "- **-1**: Vectors are completely opposite.\n",
        "- **0**: Vectors are orthogonal (uncorrelated or unrelated).\n",
        "- **1**: Vectors are identical.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c1I1TNhxYaT"
      },
      "source": [
        "<img src=\"https://storage.googleapis.com/lds-media/images/cosine-similarity-vectors.original.jpg\" alt=\"NLP Gif\" style=\"width: 700px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoEMdNgQxYaU"
      },
      "source": [
        "<h2 style=\"color: #FF6347;\">Keyword Highlighting</h2>\n",
        "\n",
        "Highlighting important keywords helps users quickly understand the relevance of the retrieved text to their query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "nCXL9Cz1xYaV"
      },
      "outputs": [],
      "source": [
        "from termcolor import colored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwDyofY0xYaV"
      },
      "source": [
        "The `highlight_keywords` function is designed to highlight specific keywords within a given text. It replaces each keyword in the text with a highlighted version using the `colored` function from the `termcolor` library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9y3E0YWExYaV"
      },
      "outputs": [],
      "source": [
        "def highlight_keywords(text, keywords):\n",
        "    for keyword in keywords:\n",
        "        text = text.replace(keyword, colored(keyword, 'green', attrs=['bold']))\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice4: add your keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "i7SkWPpnxYaW",
        "outputId": "28e82563-edba-4b41-acad-ec27e5ba134f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Snippet 1:\n",
            "lar and scholarly discussions and investigates the normative projections of what \n",
            "\u001b[1m\u001b[32mAI\u001b[0m should be and what it should do. This section poses critical questions about \n",
            "how \u001b[1m\u001b[32mAI\u001b[0m needs to debunk the myths surr\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "query_keywords = [\"AI\",\n",
        "    \"digital capitalism\",\n",
        "    \"capitalism\",\n",
        "    \"social inequalities\",\n",
        "    \"inequalities\",\n",
        "    \"power\",\n",
        "    \"labour\",\n",
        "    \"data justice\"] # add your keywords\n",
        "for i, doc in enumerate(retrieved_docs[:1]):\n",
        "    snippet = doc.page_content[:200]\n",
        "    highlighted = highlight_keywords(snippet, query_keywords)\n",
        "    print(f\"Snippet {i+1}:\\n{highlighted}\\n{'-'*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhV_Jf_LxYaX"
      },
      "source": [
        "1. `query_keywords` is a list of keywords to be highlighted.\n",
        "2. The loop iterates over the first document in retrieved_docs.\n",
        "3. For each document, a snippet of the first 200 characters is extracted.\n",
        "4. The highlight_keywords function is called to highlight the keywords in the snippet.\n",
        "5. The highlighted snippet is printed along with a separator line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBRKysAvxYaX"
      },
      "source": [
        "<h1 style=\"color: #FF6347;\">Bonus</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj25lCybxYaX"
      },
      "source": [
        "**Try loading one of your own PDF books and go through the steps again to explore how the pipeline works with your content**:\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
